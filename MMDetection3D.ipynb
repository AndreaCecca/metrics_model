{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "confidential-fleece",
   "metadata": {},
   "source": [
    "## This notebook generates the result file from mmdetection3d applied on nuscenes\n",
    "It is a by-the-book approach to use models from the mmdetection3d model zoo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-specialist",
   "metadata": {},
   "source": [
    "#### Note: nuscenes-dev (either the original version from nuscene website, or the modified version, provided by us) and mmdetection3d must be correctly installed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sweet-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes import NuScenes\n",
    "from nuscenes.eval.prediction.splits import *\n",
    "from nuscenes.eval.detection import *\n",
    "from nuscenes.eval.detection import *\n",
    "from nuscenes.eval.detection.configs import *\n",
    "\n",
    "import nuscenes.eval.detection.config as cnfig\n",
    "import nuscenes.eval.detection.evaluate as dcl\n",
    "    \n",
    "from nuscenes.prediction import *\n",
    "from nuscenes.map_expansion.map_api import *\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "allied-bench",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 42.702 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 7.5 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "DATAROOT = '/home/notebook/nuscene/data'\n",
    "nuscenes = NuScenes('v1.0-trainval', dataroot=DATAROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "naughty-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ego_list=nuscenes.ego_pose\n",
    "#curr_scene = nuscenes.scene[0]\n",
    "#nuscenes.list_scenes()\n",
    "#dir(nuscenes)\n",
    "#len(nuscenes.sample)\n",
    "#s=nuscenes.sample[0]\n",
    "#s['data']['RADAR_FRONT']\n",
    "#curr_scene\n",
    "#nuscenes.sample[0]\n",
    "#sample_curr=next(item for item in nuscenes.sample if item[\"token\"] == '30e55a3ec6184d8cb1944b39ba19d622')\n",
    "#sample_curr.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-sampling",
   "metadata": {},
   "source": [
    "#### Path of the detector and to store results\n",
    "Path to configure detector and where detector results are stored. To be configured differently for each detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "forty-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PWD; the python command is launched from this path\n",
    "PWD='/home/notebook/mmdetection3d/'\n",
    "#here we store results\n",
    "OUTPUT='/home/notebook/mmdetection3d/'\n",
    "#here we store results\n",
    "PATH='/home/notebook/mmdetection3d/pgd_results/img_bbox/'\n",
    "FILE_JSON='results_nusc.json'\n",
    "RESULT_PATH=PATH+FILE_JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-carry",
   "metadata": {},
   "source": [
    "This is simply the execution of algorithms from the mmdetection3d model zoo. Algorithms  operate on the nuscene data. So there is nothing surpising: \n",
    "\n",
    "### Available detectors\n",
    "\n",
    "#### 1 pointpillars with backbone FPN (Feature Pyramid Networks) -- LIDAR-only\n",
    "Results in: './pointpillars_nuscenes_results/pts_bbox/results_nusc-fpn.json' \n",
    "\n",
    "python tools/test.py configs/pointpillars/hv_pointpillars_fpn_sbn-all_4x8_2x_nus-3d.py checkpoints/hv_pointpillars_fpn_sbn-all_4x8_2x_nus-3d_20200620_230405-2fa62f3d.pth --format-only --options 'jsonfile_prefix=./pointpillars_nuscenes_results'\n",
    "\n",
    "mAP: 40%\n",
    "\n",
    "#### 2 pointpillars with backbone SECFPN -- LIDAR-only\n",
    "Results in: './pointpillars_nuscenes_results/pts_bbox/results_nusc-secfpn.json' \n",
    "\n",
    "python tools/test.py configs/pointpillars/hv_pointpillars_secfpn_sbn-all_4x8_2x_nus-3d.py checkpoints/hv_pointpillars_secfpn_sbn-all_4x8_2x_nus-3d_20200620_230725-0817d270.pth --format-only --options 'jsonfile_prefix=./pointpillars_nuscenes_results'\n",
    "\n",
    "mAP: 35.17%\n",
    "\n",
    "#### 3 RegNET-X (RegNET WITH RegNetX-1.6gF-FPN)\n",
    "Results in: './regnetX_nuscenes_results-secfpn/pts_bbox/results_nusc-secfpn.json'\n",
    "\n",
    "python tools/test.py configs/regnet/hv_pointpillars_regnet-1.6gf_fpn_sbn-all_4x8_2x_nus-3d.py checkpoints/hv_pointpillars_regnet-1.6gf_fpn_sbn-all_4x8_2x_nus-3d_20200629_050311-dcd4e090.pth --format-only --options 'jsonfile_prefix=./regnetX_nuscenes_results-secfpn'\n",
    "\n",
    "mAP: 48.24%\n",
    "\n",
    "#### 4 RegNET-X (RegNET WITH RegNetX-400MF-FPN)\n",
    "Results in: './regnetX_nuscenes_results-secfpn/pts_bbox/results_nusc-400MF.json'\n",
    "\n",
    "python tools/test.py configs/regnet/hv_pointpillars_regnet-400mf_fpn_sbn-all_4x8_2x_nus-3d.py checkpoints/hv_pointpillars_regnet-400mf_fpn_sbn-all_4x8_2x_nus-3d_20200620_230239-c694dce7.pth --format-only --options 'jsonfile_prefix=./regnetX_nuscenes_results-secfpn'\n",
    "\n",
    "mAP: 44.84\n",
    "\n",
    "#### 5 RegNET-X (RegNET WITH 400MF-SECFPN)\n",
    "Results in: './regnetX_nuscenes_results-secfpn/pts_bbox/results_nusc-400mfsecfpn.json'\n",
    "\n",
    "python tools/test.py configs/regnet/hv_pointpillars_regnet-400mf_secfpn_sbn-all_4x8_2x_nus-3d.py checkpoints/hv_pointpillars_regnet-400mf_secfpn_sbn-all_4x8_2x_nus-3d_20200620_230334-53044f32.pth --format-only --options 'jsonfile_prefix=./regnetX_nuscenes_results-secfpn'\n",
    "\n",
    "mAP: 41.15%\n",
    "\n",
    "#### 6 SSN with backbone SECFPN\n",
    "Results in: './ssn_nuscenes_results/pts_bbox/results_nusc-secfpn.json'\n",
    "\n",
    "python tools/test.py configs/ssn/hv_ssn_secfpn_sbn-all_2x16_2x_nus-3d.py checkpoints/hv_ssn_secfpn_sbn-all_2x16_2x_nus-3d_20201023_193737-5fda3f00.pth --format-only --options 'jsonfile_prefix=./ssn_nuscenes_results'\n",
    "\n",
    "mAP: 41.56%\n",
    "\n",
    "#### 7 SSN with backbone REGNET \n",
    "Results in: './ssn_nuscenes_results/pts_bbox/results_nusc-regnet.json'\n",
    "\n",
    "python tools/test.py configs/ssn/hv_ssn_regnet-400mf_secfpn_sbn-all_2x16_2x_nus-3d.py checkpoints/hv_ssn_regnet-400mf_secfpn_sbn-all_2x16_2x_nus-3d_20201024_232447-7af3d8c8.pth --format-only --options 'jsonfile_prefix=./ssn_nuscenes_results'\n",
    "\n",
    "mAP:46.95%\n",
    "\n",
    "#### 8 FCOSD with backbone resnet 101 (finetuned) -- camera only\n",
    "Results in './fcos_results/img_bbox/results_nusc.json'\n",
    "\n",
    "python tools/test.py configs/fcos3d/fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_finetune.py checkpoints/fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_finetune_20210427_091419-35aaaad0.pth --format-only --options 'jsonfile_prefix=./fcos_results'\n",
    "\n",
    "mAP: 32.1%\n",
    "\n",
    "#### 9 PGD with backbone resnet 101 (finetuned) -- camera only\n",
    "Results in './pgd_results/img_bbox/results_nusc.json'\n",
    "\n",
    "python tools/test.py configs/pgd/pgd_r101_caffe_fpn_gn-head_2x16_2x_nus-mono3d_finetune.py checkpoints/pgd_r101_caffe_fpn_gn-head_2x16_2x_nus-mono3d_finetune_20211114_162135-5ec7c1cd.pth --format-only --options 'jsonfile_prefix=./pgd_results'\n",
    "\n",
    "mAP: 35,8%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-regression",
   "metadata": {},
   "source": [
    "### Test the detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-tomato",
   "metadata": {},
   "source": [
    "This is the official nuScenes detection evaluation code.\n",
    "Results are written to the provided output_dir.\n",
    "nuScenes uses the following detection metrics:\n",
    "    - Mean Average Precision (mAP): Uses center-distance as matching criterion; averaged over distance thresholds.\n",
    "    - True Positive (TP) metrics: Average of translation, velocity, scale, orientation and attribute errors.\n",
    "    - nuScenes Detection Score (NDS): The weighted sum of the above.\n",
    "Here is an overview of the functions in this method:\n",
    "    - init: Loads GT annotations and predictions stored in JSON format and filters the boxes.\n",
    "    - run: Performs evaluation and dumps the metric data to disk.\n",
    "    - render: Renders various plots and dumps to disk.\n",
    "We assume that:\n",
    "    - Every sample_token is given in the results, although there may be not predictions for that sample.\n",
    "    Please see https://www.nuscenes.org/object-detection for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-vault",
   "metadata": {},
   "source": [
    "DetectionEval:\n",
    "    :param nusc: A NuScenes object.\n",
    "        :param config: A DetectionConfig object.\n",
    "        :param result_path: Path of the nuScenes JSON result file.\n",
    "        :param eval_set: The dataset split to evaluate on, e.g. train, val or test.\n",
    "        :param output_dir: Folder to save plots and results to.\n",
    "        :param verbose: Whether to print to stdout.\n",
    "\n",
    "                def main(self,\n",
    "             plot_examples: int = 0,\n",
    "             render_curves: bool = True) -> Dict[str, Any]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "running-average",
   "metadata": {},
   "outputs": [],
   "source": [
    "confvalue=cnfig.config_factory(\"detection_cvpr_2019\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-inventory",
   "metadata": {},
   "source": [
    "{\n",
    "  \"class_range\": {\n",
    "    \"car\": 50,\n",
    "    \"truck\": 50,\n",
    "    \"bus\": 50,\n",
    "    \"trailer\": 50,\n",
    "    \"construction_vehicle\": 50,\n",
    "    \"pedestrian\": 40,\n",
    "    \"motorcycle\": 40,\n",
    "    \"bicycle\": 40,\n",
    "    \"traffic_cone\": 30,\n",
    "    \"barrier\": 30\n",
    "  },\n",
    "  \"dist_fcn\": \"center_distance\",\n",
    "  \"dist_ths\": [0.5, 1.0, 2.0, 4.0],\n",
    "  \"dist_th_tp\": 2.0,\n",
    "  \"min_recall\": 0.1,\n",
    "  \"min_precision\": 0.1,\n",
    "  \"max_boxes_per_sample\": 500,\n",
    "  \"mean_ap_weight\": 5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "embedded-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of scene that compose the val set\n",
    "eval=val = \\\n",
    "    ['scene-0003', 'scene-0012', 'scene-0013', 'scene-0014', 'scene-0015', 'scene-0016', 'scene-0017', 'scene-0018',\n",
    "     'scene-0035', 'scene-0036', 'scene-0038', 'scene-0039', 'scene-0092', 'scene-0093', 'scene-0094', 'scene-0095',\n",
    "     'scene-0096', 'scene-0097', 'scene-0098', 'scene-0099', 'scene-0100', 'scene-0101', 'scene-0102', 'scene-0103',\n",
    "     'scene-0104', 'scene-0105', 'scene-0106', 'scene-0107', 'scene-0108', 'scene-0109', 'scene-0110', 'scene-0221',\n",
    "     'scene-0268', 'scene-0269', 'scene-0270', 'scene-0271', 'scene-0272', 'scene-0273', 'scene-0274', 'scene-0275',\n",
    "     'scene-0276', 'scene-0277', 'scene-0278', 'scene-0329', 'scene-0330', 'scene-0331', 'scene-0332', 'scene-0344',\n",
    "     'scene-0345', 'scene-0346', 'scene-0519', 'scene-0520', 'scene-0521', 'scene-0522', 'scene-0523', 'scene-0524',\n",
    "     'scene-0552', 'scene-0553', 'scene-0554', 'scene-0555', 'scene-0556', 'scene-0557', 'scene-0558', 'scene-0559',\n",
    "     'scene-0560', 'scene-0561', 'scene-0562', 'scene-0563', 'scene-0564', 'scene-0565', 'scene-0625', 'scene-0626',\n",
    "     'scene-0627', 'scene-0629', 'scene-0630', 'scene-0632', 'scene-0633', 'scene-0634', 'scene-0635', 'scene-0636',\n",
    "     'scene-0637', 'scene-0638', 'scene-0770', 'scene-0771', 'scene-0775', 'scene-0777', 'scene-0778', 'scene-0780',\n",
    "     'scene-0781', 'scene-0782', 'scene-0783', 'scene-0784', 'scene-0794', 'scene-0795', 'scene-0796', 'scene-0797',\n",
    "     'scene-0798', 'scene-0799', 'scene-0800', 'scene-0802', 'scene-0904', 'scene-0905', 'scene-0906', 'scene-0907',\n",
    "     'scene-0908', 'scene-0909', 'scene-0910', 'scene-0911', 'scene-0912', 'scene-0913', 'scene-0914', 'scene-0915',\n",
    "     'scene-0916', 'scene-0917', 'scene-0919', 'scene-0920', 'scene-0921', 'scene-0922', 'scene-0923', 'scene-0924',\n",
    "     'scene-0925', 'scene-0926', 'scene-0927', 'scene-0928', 'scene-0929', 'scene-0930', 'scene-0931', 'scene-0962',\n",
    "     'scene-0963', 'scene-0966', 'scene-0967', 'scene-0968', 'scene-0969', 'scene-0971', 'scene-0972', 'scene-1059',\n",
    "     'scene-1060', 'scene-1061', 'scene-1062', 'scene-1063', 'scene-1064', 'scene-1065', 'scene-1066', 'scene-1067',\n",
    "     'scene-1068', 'scene-1069', 'scene-1070', 'scene-1071', 'scene-1072', 'scene-1073']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "narrow-queensland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bronze-shaft",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing nuScenes detection evaluation\n",
      "Loaded results from /home/notebook/mmdetection3d/pgd_results/img_bbox/results_nusc.json. Found detections for 6019 samples.\n",
      "Loading annotations for val split from nuScenes version: v1.0-trainval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 6019/6019 [00:06<00:00, 878.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ground truth annotations for 6019 samples.\n",
      "Filtering predictions\n",
      "=> Original number of boxes: 530976\n",
      "=> After distance based filtering: 530740\n",
      "=> After LIDAR and RADAR points based filtering: 530740\n",
      "=> After bike rack filtering: 530368\n",
      "Filtering ground truth annotations\n",
      "=> Original number of boxes: 187528\n",
      "=> After distance based filtering: 134565\n",
      "=> After LIDAR and RADAR points based filtering: 121871\n",
      "=> After bike rack filtering: 121861\n"
     ]
    }
   ],
   "source": [
    "#execute detection on val set\n",
    "dt=dcl.DetectionEval(nuscenes,confvalue, RESULT_PATH, 'val', OUTPUT, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "banner-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(dt)\n",
    "# type(dt.gt_boxes) # nuscenes.eval.common.data_classes.EvalBoxes\n",
    "# len(dt.gt_boxes.boxes) # è 6019\n",
    "# type(dt.sample_tokens)\n",
    "# len(dt.sample_tokens) # è 6019\n",
    "# type(dt.sample_tokens[0]) # è str\n",
    "# dt.gt_boxes.boxes.values() --> dict_values([[{'sample_token': 'fd8420396768425eabec9bdddf7e64b6', 'translation': [242.87, 926.036, 0.898], 'size': [1.726, 4.257, 1.489], 'rotation': [0.787419398050721, 0.0, 0.0, -0.616417627565468], 'velocity': array([ 0.16021727, -0.69494243]), 'ego_translation': (-7.026109314307774, 8.483742683721516, 0.898), 'num_pts': 173, 'detection_name': 'car', 'detection_score': -1.0, 'attribute_name': 'vehicle.moving'}, {'sample_token': 'fd8420396768425eabec9bdddf7e64b6', 'translation': [244.281, 934.941, 1.099], 'size': [1.71, 4.248, 1.527], 'rotation': [0.7424261677818073, 0.0, 0.0, 0.6699278956670037], 'velocity': array([0., 0.]), 'ego_translation': (-5.615109314307773, 17.388742683721603, 1.099), 'num_pts': 35, 'detection_name': 'car', 'detection_score': -1.0, 'attribute_name': 'vehicle.parked'}, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "direct-leather",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulating metric data...\n",
      "Calculating metrics...\n",
      "Saving metrics to: /home/notebook/mmdetection3d/\n",
      "mAP: 0.3584\n",
      "mATE: 0.6674\n",
      "mASE: 0.2643\n",
      "mAOE: 0.4346\n",
      "mAVE: 0.9600\n",
      "mAAE: 0.1766\n",
      "NDS: 0.4289\n",
      "Eval time: 85.0s\n",
      "\n",
      "Per-class results:\n",
      "Object Class\tAP\tATE\tASE\tAOE\tAVE\tAAE\n",
      "car\t0.538\t0.514\t0.150\t0.095\t1.332\t0.140\n",
      "truck\t0.278\t0.755\t0.212\t0.146\t1.120\t0.210\n",
      "bus\t0.372\t0.702\t0.191\t0.165\t1.973\t0.295\n",
      "trailer\t0.139\t1.019\t0.237\t0.660\t0.477\t0.223\n",
      "construction_vehicle\t0.060\t0.846\t0.409\t0.984\t0.099\t0.256\n",
      "pedestrian\t0.431\t0.651\t0.290\t0.594\t0.593\t0.167\n",
      "motorcycle\t0.354\t0.633\t0.263\t0.566\t1.456\t0.112\n",
      "bicycle\t0.335\t0.618\t0.295\t0.579\t0.630\t0.010\n",
      "traffic_cone\t0.581\t0.443\t0.314\tnan\tnan\tnan\n",
      "barrier\t0.495\t0.492\t0.282\t0.121\tnan\tnan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label_aps': defaultdict(<function nuscenes.eval.detection.data_classes.DetectionMetrics.__init__.<locals>.<lambda>()>,\n",
       "             {'car': defaultdict(float,\n",
       "                          {0.5: 0.17238441152622827,\n",
       "                           1.0: 0.4495187717391653,\n",
       "                           2.0: 0.7026284591770717,\n",
       "                           4.0: 0.8276763556448701}),\n",
       "              'truck': defaultdict(float,\n",
       "                          {0.5: 0.019446003955399506,\n",
       "                           1.0: 0.14714865979999334,\n",
       "                           2.0: 0.3799788560161077,\n",
       "                           4.0: 0.5664059184995831}),\n",
       "              'bus': defaultdict(float,\n",
       "                          {0.5: 0.028375015895221865,\n",
       "                           1.0: 0.23725596599480853,\n",
       "                           2.0: 0.5249402174030049,\n",
       "                           4.0: 0.6977897910464691}),\n",
       "              'trailer': defaultdict(float,\n",
       "                          {0.5: 0.0,\n",
       "                           1.0: 0.013024938556157682,\n",
       "                           2.0: 0.161713377734678,\n",
       "                           4.0: 0.3814678499782198}),\n",
       "              'construction_vehicle': defaultdict(float,\n",
       "                          {0.5: 0.0,\n",
       "                           1.0: 0.013991883476736326,\n",
       "                           2.0: 0.07205403127361432,\n",
       "                           4.0: 0.15356240437801275}),\n",
       "              'pedestrian': defaultdict(float,\n",
       "                          {0.5: 0.10607377622351578,\n",
       "                           1.0: 0.3294724761096933,\n",
       "                           2.0: 0.568360777802783,\n",
       "                           4.0: 0.7210834131375196}),\n",
       "              'motorcycle': defaultdict(float,\n",
       "                          {0.5: 0.07667626480911338,\n",
       "                           1.0: 0.27702300704369737,\n",
       "                           2.0: 0.47635327914450953,\n",
       "                           4.0: 0.586999873248791}),\n",
       "              'bicycle': defaultdict(float,\n",
       "                          {0.5: 0.08566416762234391,\n",
       "                           1.0: 0.2583987733412062,\n",
       "                           2.0: 0.44527866990519516,\n",
       "                           4.0: 0.5523842636940914}),\n",
       "              'traffic_cone': defaultdict(float,\n",
       "                          {0.5: 0.3038122962994333,\n",
       "                           1.0: 0.550950778222816,\n",
       "                           2.0: 0.6999573141842491,\n",
       "                           4.0: 0.7681619495259316}),\n",
       "              'barrier': defaultdict(float,\n",
       "                          {0.5: 0.2008947123653315,\n",
       "                           1.0: 0.4611371194458642,\n",
       "                           2.0: 0.6237770559088867,\n",
       "                           4.0: 0.6947385622621648})}),\n",
       " 'mean_dist_aps': {'car': 0.5380519995218338,\n",
       "  'truck': 0.2782448595677709,\n",
       "  'bus': 0.3720902475848761,\n",
       "  'trailer': 0.13905154156726388,\n",
       "  'construction_vehicle': 0.05990207978209085,\n",
       "  'pedestrian': 0.4312476108183779,\n",
       "  'motorcycle': 0.3542631060615278,\n",
       "  'bicycle': 0.33543146864070916,\n",
       "  'traffic_cone': 0.5807205845581075,\n",
       "  'barrier': 0.49513686249556177},\n",
       " 'mean_ap': 0.3584140360598119,\n",
       " 'label_tp_errors': defaultdict(<function nuscenes.eval.detection.data_classes.DetectionMetrics.__init__.<locals>.<lambda>()>,\n",
       "             {'car': defaultdict(float,\n",
       "                          {'trans_err': 0.5144250174603441,\n",
       "                           'scale_err': 0.14961647003833314,\n",
       "                           'orient_err': 0.09508132692236934,\n",
       "                           'vel_err': 1.3319352670166476,\n",
       "                           'attr_err': 0.13955368780040966}),\n",
       "              'truck': defaultdict(float,\n",
       "                          {'trans_err': 0.7551344744496415,\n",
       "                           'scale_err': 0.21157127898384506,\n",
       "                           'orient_err': 0.1463768529542494,\n",
       "                           'vel_err': 1.1201263128100207,\n",
       "                           'attr_err': 0.2096732790711778}),\n",
       "              'bus': defaultdict(float,\n",
       "                          {'trans_err': 0.702208057817131,\n",
       "                           'scale_err': 0.19056987769657652,\n",
       "                           'orient_err': 0.1648925567253958,\n",
       "                           'vel_err': 1.9726177821904167,\n",
       "                           'attr_err': 0.29499273934076436}),\n",
       "              'trailer': defaultdict(float,\n",
       "                          {'trans_err': 1.0188053842956395,\n",
       "                           'scale_err': 0.23716182455322218,\n",
       "                           'orient_err': 0.6603371173603452,\n",
       "                           'vel_err': 0.4768831913529866,\n",
       "                           'attr_err': 0.22327239388169187}),\n",
       "              'construction_vehicle': defaultdict(float,\n",
       "                          {'trans_err': 0.8460605394468014,\n",
       "                           'scale_err': 0.40926808967084777,\n",
       "                           'orient_err': 0.9839668960486899,\n",
       "                           'vel_err': 0.09940855992766265,\n",
       "                           'attr_err': 0.2559526275466826}),\n",
       "              'pedestrian': defaultdict(float,\n",
       "                          {'trans_err': 0.6513744490825325,\n",
       "                           'scale_err': 0.2902828014345677,\n",
       "                           'orient_err': 0.5944975999663189,\n",
       "                           'vel_err': 0.5933652024817799,\n",
       "                           'attr_err': 0.16728559085573022}),\n",
       "              'motorcycle': defaultdict(float,\n",
       "                          {'trans_err': 0.6327676522945855,\n",
       "                           'scale_err': 0.26328540333893463,\n",
       "                           'orient_err': 0.5655751014426861,\n",
       "                           'vel_err': 1.4555963686980167,\n",
       "                           'attr_err': 0.11217179372692096}),\n",
       "              'bicycle': defaultdict(float,\n",
       "                          {'trans_err': 0.6182562620934013,\n",
       "                           'scale_err': 0.2949955199098499,\n",
       "                           'orient_err': 0.579260665365752,\n",
       "                           'vel_err': 0.6304195542218574,\n",
       "                           'attr_err': 0.010246415672979209}),\n",
       "              'traffic_cone': defaultdict(float,\n",
       "                          {'trans_err': 0.4427684679919351,\n",
       "                           'scale_err': 0.31435102759401473,\n",
       "                           'orient_err': nan,\n",
       "                           'vel_err': nan,\n",
       "                           'attr_err': nan}),\n",
       "              'barrier': defaultdict(float,\n",
       "                          {'trans_err': 0.49202193977528097,\n",
       "                           'scale_err': 0.28190396315361205,\n",
       "                           'orient_err': 0.12105418808863026,\n",
       "                           'vel_err': nan,\n",
       "                           'attr_err': nan})}),\n",
       " 'tp_errors': {'trans_err': 0.6673822244707293,\n",
       "  'scale_err': 0.26430062563738044,\n",
       "  'orient_err': 0.4345602560971597,\n",
       "  'vel_err': 0.9600440298374235,\n",
       "  'attr_err': 0.17664356598704462},\n",
       " 'tp_scores': {'trans_err': 0.33261777552927074,\n",
       "  'scale_err': 0.7356993743626196,\n",
       "  'orient_err': 0.5654397439028402,\n",
       "  'vel_err': 0.03995597016257646,\n",
       "  'attr_err': 0.8233564340129553},\n",
       " 'nd_score': 0.42891394782693215,\n",
       " 'eval_time': 84.99713253974915,\n",
       " 'cfg': {'class_range': {'car': 50,\n",
       "   'truck': 50,\n",
       "   'bus': 50,\n",
       "   'trailer': 50,\n",
       "   'construction_vehicle': 50,\n",
       "   'pedestrian': 40,\n",
       "   'motorcycle': 40,\n",
       "   'bicycle': 40,\n",
       "   'traffic_cone': 30,\n",
       "   'barrier': 30},\n",
       "  'dist_fcn': 'center_distance',\n",
       "  'dist_ths': [0.5, 1.0, 2.0, 4.0],\n",
       "  'dist_th_tp': 2.0,\n",
       "  'min_recall': 0.1,\n",
       "  'min_precision': 0.1,\n",
       "  'max_boxes_per_sample': 500,\n",
       "  'mean_ap_weight': 5},\n",
       " 'meta': {'use_lidar': False,\n",
       "  'use_camera': True,\n",
       "  'use_radar': False,\n",
       "  'use_map': False,\n",
       "  'use_external': False}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.main(plot_examples=0,render_curves=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-pilot",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmm1",
   "language": "python",
   "name": "mmm1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
